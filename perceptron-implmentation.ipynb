{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning Fundamentals Assignment - David Sackett.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI6lnalK0thf"
      },
      "source": [
        "# Imports required for all steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGABUnD4zqAe"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRt0B1K50oYT"
      },
      "source": [
        "# Preceptron Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3dndmPB0Yp9"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, max_iterations=100, learning_rate=0.001):\n",
        "        \"\"\"\n",
        "        The constructor method of an object.\n",
        "        \"\"\"\n",
        "        # the perceptron's weights. Initialised by .fit()\n",
        "        self._w = None\n",
        "        self._learning_rate = learning_rate\n",
        "        self._max_iterations = max_iterations\n",
        "\n",
        "    def _add_constant(self, X):\n",
        "        '''Add dummy constant attribute to all samples'''\n",
        "        num_samples = X.shape[0]\n",
        "        X0 = np.transpose([np.ones(num_samples)])\n",
        "        X = np.concatenate([X, X0], axis=1)\n",
        "\n",
        "        return X\n",
        "\n",
        "    def accurancy(self, y, predicted):\n",
        "        '''return the accurancy of a given set of predictions'''\n",
        "        correct_classifications = np.sum(y == predicted)\n",
        "\n",
        "        return correct_classifications / len(y)\n",
        "            \n",
        "    def predict(self, X):\n",
        "        '''predicts y for all samples X'''\n",
        "        # add the constant dummy value to each sample to make\n",
        "        # it possible to perform all calculations using matrix\n",
        "        # algebra\n",
        "        X = self._add_constant(X)\n",
        "        \n",
        "        # perform the prediction and return it\n",
        "        return self._predict(X)\n",
        "\n",
        "    def _predict(self, X):\n",
        "        '''predicts y for all samples X\n",
        "        \n",
        "        assumes that the dummy values have already been applied\n",
        "        '''\n",
        "        # equivalent to applying the weights to each data sample\n",
        "        # and summing\n",
        "        y = np.dot(X, self._w)\n",
        "        \n",
        "        # apply the threshold function\n",
        "        y = np.where(y >= 0.0, 1, -1)\n",
        "        \n",
        "        return y\n",
        "    \n",
        "    def fit(self, X, y, quiet=True):\n",
        "        \"\"\"\n",
        "        :param X: training data samples\n",
        "        :param y: the target values\n",
        "        :param quiet: if true do not print any output while learning\n",
        "        \"\"\"\n",
        "        # initialise weights based on the number of inputs in X\n",
        "        # this allows us to support data sets with different\n",
        "        # numbers of inputs\n",
        "        self._w = np.zeros(X.shape[1] + 1)\n",
        "        \n",
        "        # add the constant dummy value to each sample to make\n",
        "        # it possible to perform all calculations using matrix\n",
        "        # algebra\n",
        "        X = self._add_constant(X)\n",
        "\n",
        "        # counter used to track the number of iterations. We\n",
        "        # stop the learning when max_iterations is reached.\n",
        "        iterations = 0\n",
        "\n",
        "        while True:\n",
        "            # predict using current weights\n",
        "            predicted = self._predict(X)\n",
        "\n",
        "            # count the number of errors for using the current weights\n",
        "            # to predict the target values y for all samples X\n",
        "            errors = 0\n",
        "            \n",
        "            # loop through each data sample, its target and our prediction\n",
        "            for xi, yi, predi in zip(X, y, predicted):\n",
        "                # calculate the update to make based on the difference between\n",
        "                # target and prediction. Multiply by the learning rate to\n",
        "                # improve convergence.\n",
        "                update = self._learning_rate * (yi - predi)\n",
        "                \n",
        "                # update the weights\n",
        "                self._w += update * xi\n",
        "                \n",
        "                # store the number of errors for this sample\n",
        "                errors += int(update != 0.0)\n",
        "            \n",
        "            # produce some output to show how low the learning process is\n",
        "            # progressing\n",
        "            accurancy = self.accurancy(y, predicted)\n",
        "            if not quiet:\n",
        "              print(f'iterations: {iterations} weights: {self._w} ' +\n",
        "                    f'errors: {errors} accuracy: {accurancy:.2f}')\n",
        "\n",
        "            # increment the iteration count and stop learning if we've reached\n",
        "            # max_iterations.\n",
        "            iterations += 1\n",
        "            if iterations > self._max_iterations:\n",
        "                break"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqDb0V9x0_Ds"
      },
      "source": [
        "# Data Set 1: Iris\n",
        "## Training and Test data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfQib9Go1D5v"
      },
      "source": [
        "# The Iris dataset will be used to demonstrate that the\n",
        "# perceptron works with 2 classes and 5 inputs.\n",
        "\n",
        "# load the iris data set\n",
        "iris = load_iris()\n",
        "X, y = iris['data'], iris['target']\n",
        "\n",
        "# Reduce the classification from ['setosa', 'versicolor', 'virginica']\n",
        "# to ['not virginica', 'virginica']\n",
        "two_class_index = np.logical_or(y == 0, y == 1)\n",
        "simple_X = X[two_class_index]\n",
        "simple_y = y[two_class_index]\n",
        "\n",
        "# It is more convenient for the implementation if the output is 1 or -1 rather\n",
        "# than 1 or 0. Convert all the 0's to -1's.\n",
        "simple_y[simple_y==0] = -1\n",
        "\n",
        "# Split that data into training and testing sets\n",
        "simple_X_train, simple_X_valid, simple_y_train, simple_y_valid = \\\n",
        "    train_test_split(simple_X, simple_y)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I20O_9f1CpiG"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWSAIECl2zYu"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9QKLQPu1eg5",
        "outputId": "ca3aa1e1-e397-4ab3-971f-8cb80b831bc9"
      },
      "source": [
        "# create the Perceptron model\n",
        "model = Perceptron()\n",
        "\n",
        "# train the model\n",
        "# the default options are:\n",
        "# - max_iterations = 100\n",
        "# - learning_rate  = 0.001\n",
        "# - quiet          = True\n",
        "model.fit(simple_X_train, simple_y_train, quiet=False)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iterations: 0 weights: [-0.3718 -0.2546 -0.1092 -0.0182 -0.074 ] errors: 37 accuracy: 0.51\n",
            "iterations: 1 weights: [ 0.078  -0.0432  0.2116  0.0814  0.002 ] errors: 38 accuracy: 0.49\n",
            "iterations: 2 weights: [-0.2938 -0.2978  0.1024  0.0632 -0.072 ] errors: 37 accuracy: 0.51\n",
            "iterations: 3 weights: [ 0.156  -0.0864  0.4232  0.1628  0.004 ] errors: 38 accuracy: 0.49\n",
            "iterations: 4 weights: [-0.2158 -0.341   0.314   0.1446 -0.07  ] errors: 37 accuracy: 0.51\n",
            "iterations: 5 weights: [ 0.234  -0.1296  0.6348  0.2442  0.006 ] errors: 38 accuracy: 0.49\n",
            "iterations: 6 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 37 accuracy: 0.51\n",
            "iterations: 7 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 8 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 9 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 10 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 11 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 12 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 13 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 14 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 15 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 16 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 17 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 18 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 19 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 20 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 21 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 22 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 23 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 24 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 25 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 26 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 27 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 28 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 29 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 30 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 31 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 32 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 33 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 34 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 35 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 36 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 37 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 38 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 39 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 40 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 41 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 42 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 43 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 44 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 45 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 46 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 47 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 48 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 49 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 50 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 51 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 52 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 53 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 54 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 55 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 56 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 57 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 58 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 59 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 60 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 61 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 62 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 63 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 64 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 65 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 66 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 67 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 68 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 69 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 70 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 71 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 72 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 73 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 74 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 75 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 76 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 77 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 78 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 79 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 80 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 81 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 82 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 83 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 84 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 85 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 86 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 87 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 88 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 89 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 90 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 91 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 92 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 93 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 94 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 95 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 96 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 97 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 98 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 99 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n",
            "iterations: 100 weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ] errors: 0 accuracy: 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke5gaTj030xu"
      },
      "source": [
        "## Validate The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUWsY5At1-Ov",
        "outputId": "d7dfccbf-25f3-498c-b1b6-bfd3e59a2dd7"
      },
      "source": [
        "print(f'Model weights: {model._w}')\n",
        "pred_train = model.predict(simple_X_train)\n",
        "training_accuracy = model.accurancy(simple_y_train, pred_train)\n",
        "print(f'Accuracy of the predictor on the *training* data set: {training_accuracy:.2f}')\n",
        "\n",
        "pred_valid = model.predict(simple_X_valid)\n",
        "validation_accuracy = model.accurancy(simple_y_valid, pred_valid)\n",
        "print(f'Accuracy of the predictor on the *test* data set: {validation_accuracy:.2f}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model weights: [-0.1378 -0.3842  0.5256  0.226  -0.068 ]\n",
            "Accuracy of the predictor on the *training* data set: 1.00\n",
            "Accuracy of the predictor on the *test* data set: 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRWr2aFsFFIe"
      },
      "source": [
        "# Data Set 2: Australian Weather data\n",
        "\n",
        "This data set includes various weather metrics and whether there is rain tomorrow. We will use this data set to train a classifier to predict whether there will be rain tomorrow.\n",
        "\n",
        "Data set used: https://www.kaggle.com/jsphyg/weather-dataset-rattle-package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUaoCmW539EU",
        "outputId": "622813a8-f4e2-4ce5-bb93-3300f3a7b34c"
      },
      "source": [
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "data = pd.read_csv('weatherAUS.csv')\n",
        "# the following line can be used to see all the cities in the data set and\n",
        "# now many samples are available for each city.\n",
        "# print(data['Location'].value_counts())\n",
        "\n",
        "# filter down to a single city. In this case Melbourne\n",
        "cityFilter = data['Location'] == 'Melbourne'\n",
        "\n",
        "# the following line can be used to see how many samples we have\n",
        "# what the available columns are, their types and how may non-null\n",
        "# values\n",
        "# print(cityData.info())\n",
        "\n",
        "# remove any samples with missing data. I.e. NaN\n",
        "cityData = data[cityFilter].dropna()\n",
        "\n",
        "# select some interesting columns that are floats and may help\n",
        "# us predict the target\n",
        "simple_X = cityData[['MinTemp',\n",
        "                     'MaxTemp',\n",
        "                     'Rainfall',\n",
        "                     'Pressure9am',\n",
        "                     'Pressure3pm',\n",
        "                     'Temp9am',\n",
        "                     'Temp3pm']].to_numpy()\n",
        "\n",
        "# use the rain tomorrow column as our target\n",
        "# convert the Yes value to 1 or 0\n",
        "simple_y = (cityData['RainTomorrow'].to_numpy()=='Yes').astype(int)\n",
        "\n",
        "# convert 1/0 to 1/-1\n",
        "simple_y[simple_y==0] = -1\n",
        "\n",
        "# split the data into training set and test set\n",
        "simple_X_train, simple_X_valid, simple_y_train, simple_y_valid = \\\n",
        "    train_test_split(simple_X, simple_y, random_state=42)\n",
        "\n",
        "# count the number of unique targets in our data set\n",
        "unique_values = np.unique(simple_y, return_counts=True)\n",
        "print(f'Number of samples is {len(simple_y)}')\n",
        "for target_value, count in zip(unique_values[0], unique_values[1]):\n",
        "  print(f'Number of samples with a target value of {target_value} is {count}')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples is 1898\n",
            "Number of samples with a target value of -1 is 1427\n",
            "Number of samples with a target value of 1 is 471\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alGj_5z0FZhS",
        "outputId": "6422e652-cada-4ba1-d772-da0c78e76c79"
      },
      "source": [
        "model2 = Perceptron(max_iterations=1000, learning_rate=0.01) # initiate an object\n",
        "model2.fit(simple_X_train, simple_y_train, quiet=True)\n",
        "\n",
        "print('Model weights', model._w)\n",
        "pred_train = model2.predict(simple_X_train)\n",
        "training_accuracy = model.accurancy(simple_y_train, pred_train)\n",
        "print(f'Accuracy of the predictor on the training data set: {training_accuracy:.2f}')\n",
        "\n",
        "pred_valid = model2.predict(simple_X_valid)\n",
        "validation_accuracy = model2.accurancy(simple_y_valid, pred_valid)\n",
        "print(f'Accuracy of the predictor on the test data set: {validation_accuracy:.2f}')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model weights [-0.1378 -0.3842  0.5256  0.226  -0.068 ]\n",
            "Accuracy of the predictor on the training data set: 0.73\n",
            "Accuracy of the predictor on the test data set: 0.80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyxWfB3XIpfw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}